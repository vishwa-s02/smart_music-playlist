<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Gesture Music Player</title>
<style>
  body { margin:0; font-family: Arial,sans-serif; text-align:center; background: linear-gradient(120deg, #ff512f, #dd2476); color:white;}
  h1 { margin-top: 20px; }
  #webcam { border:5px solid white; border-radius:12px; margin-top:20px; }
  #status { font-size:22px; margin-top:15px; font-weight:bold; }
  audio { margin-top:20px; outline:none; }
  #volumeContainer { width:300px; height:20px; background: rgba(255,255,255,0.3); border-radius:10px; margin:10px auto; }
  #volumeBar { width:50%; height:100%; background:#00ff00; border-radius:10px; transition:width 0.1s; }
</style>
</head>
<body>
<h1>ðŸŽµ Gesture Music Player</h1>
<video id="webcam" width="400" height="300" autoplay></video>
<div id="status">Waiting for gesture...</div>
<audio id="player" controls>
  <source src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3" type="audio/mpeg">
</audio>
<div id="volumeContainer">
  <div id="volumeBar"></div>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

<script>
const video = document.getElementById("webcam");
const statusDiv = document.getElementById("status");
const player = document.getElementById("player");
const volumeBar = document.getElementById("volumeBar");
let model;

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({video:true});
  video.srcObject = stream;
  return new Promise(resolve=>{video.onloadedmetadata=()=>resolve(video);});
}

// Gestures
function isThumbUp(landmarks){ return landmarks[4][1] < landmarks[2][1]; }
function isThumbDown(landmarks){ return landmarks[4][1] > landmarks[2][1]; }
function isIndexUp(landmarks){ return landmarks[8][1] < landmarks[6][1]; }
function isIndexDown(landmarks){ return landmarks[8][1] > landmarks[6][1]; }

function updateVolumeBar(){ volumeBar.style.width = (player.volume*100) + "%"; }

async function detectHands(){
  const predictions = await model.estimateHands(video);
  if(predictions.length>0){
    const landmarks = predictions[0].landmarks;

    if(isThumbUp(landmarks)){
      player.pause();
      statusDiv.innerText="âœ‹ Thumb Up â†’ Paused";
    } else if(isThumbDown(landmarks)){
      player.play();
      statusDiv.innerText="ðŸ‘‡ Thumb Down â†’ Playing";
    } else if(isIndexUp(landmarks)){
      player.volume = Math.min(player.volume+0.01,1);
      statusDiv.innerText="â˜ï¸ Index Up â†’ Volume: "+Math.round(player.volume*100)+"%";
      updateVolumeBar();
    } else if(isIndexDown(landmarks)){
      player.volume = Math.max(player.volume-0.01,0);
      statusDiv.innerText="ðŸ‘‡ Index Down â†’ Volume: "+Math.round(player.volume*100)+"%";
      updateVolumeBar();
    } else{
      statusDiv.innerText="Waiting for gesture...";
    }
  }
  requestAnimationFrame(detectHands);
}

async function main(){
  await navigator.mediaDevices.getUserMedia({video:true}).then(stream=>{video.srcObject=stream;});
  model = await handpose.load();
  detectHands();
  updateVolumeBar();
}

main();
</script>
</body>
</html>
